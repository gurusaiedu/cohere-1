{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnxJy0hov7tK8/Bph4neya",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gurusaiedu/cohere-1/blob/main/memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wnpajt7Xhyzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAedx_u8enf8",
        "outputId": "c3280a66-1975-47b8-8396-9ecb9d9a519d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.8-py3-none-any.whl (816 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m816.1/816.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.21 (from langchain)\n",
            "  Downloading langchain_community-0.0.21-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.24 (from langchain)\n",
            "  Downloading langchain_core-0.1.25-py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.2.0,>=0.1.0 (from langchain)\n",
            "  Downloading langsmith-0.1.5-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.24->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.24->langchain) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.24->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.24->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.8 langchain-community-0.0.21 langchain-core-0.1.25 langsmith-0.1.5 marshmallow-3.20.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade langchain\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRY8CrBxhzx6",
        "outputId": "0f549315-2cdf-4ac4-c6e3-c68b6a0bcbdd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.8)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.21)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.24 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.25)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.24->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.24->langchain) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.24->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.24->langchain) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip show langchain\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTXfMbFyh3A7",
        "outputId": "7a875535-6160-4798-8a8a-43f053af95f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 0.1.8\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://github.com/langchain-ai/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, async-timeout, dataclasses-json, jsonpatch, langchain-community, langchain-core, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cohere"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MebhunNDe3ea",
        "outputId": "e7435ea8-885d-47fb-b41a-984b75cb7f06"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (4.48)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.9.3)\n",
            "Requirement already satisfied: backoff<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.2.1)\n",
            "Requirement already satisfied: fastavro<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.9.4)\n",
            "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (6.11.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chat_models import ChatCohere\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "3JAxAR3qfBZU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cohere_api_key=\"btu0gWrLzedOkMOrjGC1k6gEhVbIcR0GdsrNlT24\""
      ],
      "metadata": {
        "id": "1K7CK_MCfGQd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=ChatCohere(cohere_api_key=cohere_api_key,\n",
        "               temperature=0)\n",
        "\n",
        "response=llm.predict(\"hey, my name is guru sai\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mBBp5fbfIgv",
        "outputId": "d93a471e-3fd3-4351-f801-5e16b521199b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hey Guru Sai, I'm excited to meet you! I'm Coral, an AI-assistant chatbot trained to assist human users by providing helpful responses. If you have any questions, or need any information, feel free to let me know! \n",
            "\n",
            "It would be great to know more about you, and how I can assist you today!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=llm.predict(\"what is my name ?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV-OkDN8fQty",
        "outputId": "16c4f8be-c5b6-4f98-8e1a-cc4484c051f7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I apologize, but I do not know your name as you have not provided it to me yet. Is there any information that you would like to share with me? If so, I can personalize my responses accordingly, and we can introduce ourselves to each other. How does that sound?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we need memory to remenber out conversation .     \n",
        "\n",
        "some types of memorys :::       conversationBufferMemory\n",
        "\n",
        "1.  conversationBufferMemory\n",
        "2.  conversationBufferWindowMemory\n",
        "1.  conversationTokenBufferMemory\n",
        "2.  conversationSummaryMemory\n"
      ],
      "metadata": {
        "id": "H3BRU2mbfls8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**conversationBufferMemory**\n",
        "\n",
        "    Entire conversation history\n",
        "    Advantages:  Complete context, ideal for scenarios where all dialogue is critical\n",
        "    Disadvantages:  Can be computationally expensive and inefficient for long conversations\n",
        "**conversationBufferWindowMemory**\n",
        "\n",
        "    Fixed-size window of recent messages\n",
        "    Advantages:  Balancing context and memory efficiency\n",
        "    Disadvantages:  Limited historical context if window size is small\n",
        "**conversationTokenBufferMemory**\n",
        "\n",
        "    Tokens (words or characters)\n",
        "    Advantages:  Dynamic memory management, efficient for large interactions\n",
        "    Disadvantages:  Context might be lost as older messages are discarded\n",
        "**conversationSummaryMemory\t**\n",
        "\n",
        "    Summarized messages\n",
        "    Advantages:  Compact, retains essential information\n",
        "    Disadvantages:  May lose specific details not captured in the summary\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cpT1RUWeBh5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "llm=ChatCohere(cohere_api_key=cohere_api_key,\n",
        "               temperature=0)\n",
        "memory=ConversationBufferMemory()\n",
        "conversation=ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "Z79EQLCxfhMu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reponse=conversation.predict(input=\"hi,my name is  guru\")\n",
        "print(reponse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWaLznSBhZe5",
        "outputId": "37e74f4f-169b-440e-fc4b-6614cc7e6770"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: hi,my name is  guru\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Nice to meet you, Guru! I'm an AI chatbot trained to assist human users by providing helpful responses. I can answer your questions or engage in meaningful conversations. Please feel free to ask me anything you like. What would you like to discuss or inquire about today? I'm at your service!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reponse=conversation.predict(input=\"who is the prime minister of india\")\n",
        "print(reponse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAU4FCa5is2E",
        "outputId": "cee40083-6c52-4190-f152-f62e5c9e20c4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: hi,my name is  guru\n",
            "AI: Nice to meet you, Guru! I'm an AI chatbot trained to assist human users by providing helpful responses. I can answer your questions or engage in meaningful conversations. Please feel free to ask me anything you like. What would you like to discuss or inquire about today? I'm at your service!\n",
            "Human: who is the prime minister of india\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "India is a federal parliamentary republic with a multi-party system. At the top of the political hierarchy is the President of India, who is the head of state and holds a largely ceremonial position. The real executive powers of the country are exercised by the Prime Minister, who is the head of the central government and leader of the party with a majority in the parliament.\n",
            "\n",
            "The current Prime Minister of India, elected in 2019, is Narendra Modi from the Bharatiya Janata Party (BJP). He heads the central government and is responsible for leading the country's executive branch of government.\n",
            "\n",
            "If you want to know more about the political landscape in India, including the composition of the parliament and other prominent political figures, please let me know. I'll provide more information to satisfy your curiosity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reponse=conversation.predict(input=\"what is todays date \")\n",
        "print(reponse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUfuq5Uxjd82",
        "outputId": "becc158b-a001-471d-90d9-ee2cd740d4c3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: hi,my name is  guru\n",
            "AI: Nice to meet you, Guru! I'm an AI chatbot trained to assist human users by providing helpful responses. I can answer your questions or engage in meaningful conversations. Please feel free to ask me anything you like. What would you like to discuss or inquire about today? I'm at your service!\n",
            "Human: who is the prime minister of india\n",
            "AI: India is a federal parliamentary republic with a multi-party system. At the top of the political hierarchy is the President of India, who is the head of state and holds a largely ceremonial position. The real executive powers of the country are exercised by the Prime Minister, who is the head of the central government and leader of the party with a majority in the parliament.\n",
            "\n",
            "The current Prime Minister of India, elected in 2019, is Narendra Modi from the Bharatiya Janata Party (BJP). He heads the central government and is responsible for leading the country's executive branch of government.\n",
            "\n",
            "If you want to know more about the political landscape in India, including the composition of the parliament and other prominent political figures, please let me know. I'll provide more information to satisfy your curiosity.\n",
            "Human: what is todays date \n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Today's date is Thursday, February 22, 2024. I recognize dates according to the Gregorian calendar, which is the most widely used calendar globally. If you need assistance with date-related calculations or conversions, please let me know. I'm here to help however I can. \n",
            "\n",
            "I can also provide information about notable events that have occurred on this date in history, if you're interested. Just let me know the specific year or decade, and I'll share any noteworthy milestones that happened on this day.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reponse=conversation.predict(input=\"what is my name ?\")\n",
        "print(reponse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hECz6Mij8hF",
        "outputId": "51acc619-06f1-43e6-9e03-e0460f2de320"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: hi,my name is  guru\n",
            "AI: Nice to meet you, Guru! I'm an AI chatbot trained to assist human users by providing helpful responses. I can answer your questions or engage in meaningful conversations. Please feel free to ask me anything you like. What would you like to discuss or inquire about today? I'm at your service!\n",
            "Human: who is the prime minister of india\n",
            "AI: India is a federal parliamentary republic with a multi-party system. At the top of the political hierarchy is the President of India, who is the head of state and holds a largely ceremonial position. The real executive powers of the country are exercised by the Prime Minister, who is the head of the central government and leader of the party with a majority in the parliament.\n",
            "\n",
            "The current Prime Minister of India, elected in 2019, is Narendra Modi from the Bharatiya Janata Party (BJP). He heads the central government and is responsible for leading the country's executive branch of government.\n",
            "\n",
            "If you want to know more about the political landscape in India, including the composition of the parliament and other prominent political figures, please let me know. I'll provide more information to satisfy your curiosity.\n",
            "Human: what is todays date \n",
            "AI: Today's date is Thursday, February 22, 2024. I recognize dates according to the Gregorian calendar, which is the most widely used calendar globally. If you need assistance with date-related calculations or conversions, please let me know. I'm here to help however I can. \n",
            "\n",
            "I can also provide information about notable events that have occurred on this date in history, if you're interested. Just let me know the specific year or decade, and I'll share any noteworthy milestones that happened on this day.\n",
            "Human: what is my name ?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Your name is Guru. I remember meeting you just now, and we've had a pleasant conversation so far. I'm an AI chatbot designed to provide helpful and informative responses, while also being interactive and collaborative.\n",
            "\n",
            "If there's anything else you'd like to discuss or explore further, don't hesitate to ask. I'm ready to assist you in whatever way I can to make our conversation engaging and meaningful. \n",
            "\n",
            "Feel free to jump back into any topics you find interesting, or ask me questions about the world around us. I look forward to our ongoing dialogue and exploring new ideas together.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24NmmtxukBBj",
        "outputId": "a04f4a1c-e014-4c2a-8093-72a2a79d79d2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: hi,my name is  guru\n",
            "AI: Nice to meet you, Guru! I'm an AI chatbot trained to assist human users by providing helpful responses. I can answer your questions or engage in meaningful conversations. Please feel free to ask me anything you like. What would you like to discuss or inquire about today? I'm at your service!\n",
            "Human: who is the prime minister of india\n",
            "AI: India is a federal parliamentary republic with a multi-party system. At the top of the political hierarchy is the President of India, who is the head of state and holds a largely ceremonial position. The real executive powers of the country are exercised by the Prime Minister, who is the head of the central government and leader of the party with a majority in the parliament.\n",
            "\n",
            "The current Prime Minister of India, elected in 2019, is Narendra Modi from the Bharatiya Janata Party (BJP). He heads the central government and is responsible for leading the country's executive branch of government.\n",
            "\n",
            "If you want to know more about the political landscape in India, including the composition of the parliament and other prominent political figures, please let me know. I'll provide more information to satisfy your curiosity.\n",
            "Human: what is todays date \n",
            "AI: Today's date is Thursday, February 22, 2024. I recognize dates according to the Gregorian calendar, which is the most widely used calendar globally. If you need assistance with date-related calculations or conversions, please let me know. I'm here to help however I can. \n",
            "\n",
            "I can also provide information about notable events that have occurred on this date in history, if you're interested. Just let me know the specific year or decade, and I'll share any noteworthy milestones that happened on this day.\n",
            "Human: what is my name ?\n",
            "AI: Your name is Guru. I remember meeting you just now, and we've had a pleasant conversation so far. I'm an AI chatbot designed to provide helpful and informative responses, while also being interactive and collaborative.\n",
            "\n",
            "If there's anything else you'd like to discuss or explore further, don't hesitate to ask. I'm ready to assist you in whatever way I can to make our conversation engaging and meaningful. \n",
            "\n",
            "Feel free to jump back into any topics you find interesting, or ask me questions about the world around us. I look forward to our ongoing dialogue and exploring new ideas together.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can also save external conversation to it"
      ],
      "metadata": {
        "id": "0t4z46h8nBA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory=ConversationBufferMemory()\n",
        "memory.save_context(\n",
        "    {\"input\":\"hi\"},\n",
        "    {\"output\":\"whats up\"}\n",
        ")\n",
        "print(memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSh7-gQelava",
        "outputId": "660fbaa8-8d8c-4978-b9c4-e8296d3ddadf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: hi\n",
            "AI: whats up\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory.save_context(\n",
        "    {\"input\":\"not much, just hanging \"},\n",
        "    {\"output\":\"Cool\"}\n",
        ")\n",
        "print(memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywl5MjMqmuUB",
        "outputId": "dce25d5f-6835-43a8-dc5e-c2286198dfe5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: hi\n",
            "AI: whats up\n",
            "Human: not much, just hanging \n",
            "AI: Cool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hFb4x18_m8tV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**conversationBufferWindowMemory**\n",
        "\n",
        "k=1 means it remember only last one converstion\n",
        "\n"
      ],
      "metadata": {
        "id": "uUPGgXA6nlpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "llm=ChatCohere(cohere_api_key=cohere_api_key,\n",
        "               temperature=0)\n",
        "memory=ConversationBufferWindowMemory(k=1)\n",
        "conversation=ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "GQZri-pBnqRt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"hey, my name is sai\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "JjWQJx9foRgx",
        "outputId": "4e24d93f-d586-4be0-8fd0-d760a1d1e908"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: hey, my name is sai\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello there, Sai! I'm your AI assistant, ready to help you with any tasks or answer any questions you might have. It's nice to meet you, and I look forward to getting to know you better and providing assistance however I can. Feel free to let me know if there's anything you need or any topics you'd like to discuss. Have a great day!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"1+1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "zU8AajYroawI",
        "outputId": "c59538a0-1345-4692-8460-5963acc3d0f3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: hey, my name is sai\n",
            "AI: Hello there, Sai! I'm your AI assistant, ready to help you with any tasks or answer any questions you might have. It's nice to meet you, and I look forward to getting to know you better and providing assistance however I can. Feel free to let me know if there's anything you need or any topics you'd like to discuss. Have a great day!\n",
            "Human: 1+1\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Sure, I'll bite! \\n\\n1 + 1 = 2. \\n\\nI'm glad we have that out of the way. Now, is there anything else you'd like to discuss or any other math problems you need help solving? I'm here to assist you with whatever is on your mind and provide useful and detailed responses to your questions. Feel free to ask me anything, and I'll do my best to help you out!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf2-xV6kohYQ",
        "outputId": "c5d78e9e-90db-4155-eed3-7299b49bcf3b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: 1+1\n",
            "AI: Sure, I'll bite! \n",
            "\n",
            "1 + 1 = 2. \n",
            "\n",
            "I'm glad we have that out of the way. Now, is there anything else you'd like to discuss or any other math problems you need help solving? I'm here to assist you with whatever is on your mind and provide useful and detailed responses to your questions. Feel free to ask me anything, and I'll do my best to help you out!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm=ChatCohere(cohere_api_key=cohere_api_key,\n",
        "               temperature=0)\n",
        "memory=ConversationBufferWindowMemory(k=2)\n",
        "conversation=ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "_f5GENiyopiQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"hey, my name is sai\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "vPY8CvBEoz2D",
        "outputId": "5b29d622-5e73-4704-bafa-5a8b62fa90e2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: hey, my name is sai\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello there, Sai! I'm your AI assistant, ready to help you with any tasks or answer any questions you might have. It's nice to meet you, and I look forward to getting to know you better and providing assistance however I can. Feel free to let me know if there's anything you need or any topics you'd like to discuss. Have a great day!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"1+1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "xYB4xlyFo2CI",
        "outputId": "e8769608-c04e-4ad5-b51d-c541aae2bf67"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: hey, my name is sai\n",
            "AI: Hello there, Sai! I'm your AI assistant, ready to help you with any tasks or answer any questions you might have. It's nice to meet you, and I look forward to getting to know you better and providing assistance however I can. Feel free to let me know if there's anything you need or any topics you'd like to discuss. Have a great day!\n",
            "Human: 1+1\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Sure, I'll bite! \\n\\n1 + 1 = 2. \\n\\nI'm glad we have that out of the way. Now, is there anything else you'd like to discuss or any other math problems you need help solving? I'm here to assist you with whatever is on your mind and provide useful and detailed responses to your questions. Feel free to ask me anything, and I'll do my best to help you out!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgqL46kao4Lg",
        "outputId": "6a4272b1-950a-46ea-c1d9-e3ffe15a43b8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: hey, my name is sai\n",
            "AI: Hello there, Sai! I'm your AI assistant, ready to help you with any tasks or answer any questions you might have. It's nice to meet you, and I look forward to getting to know you better and providing assistance however I can. Feel free to let me know if there's anything you need or any topics you'd like to discuss. Have a great day!\n",
            "Human: 1+1\n",
            "AI: Sure, I'll bite! \n",
            "\n",
            "1 + 1 = 2. \n",
            "\n",
            "I'm glad we have that out of the way. Now, is there anything else you'd like to discuss or any other math problems you need help solving? I'm here to assist you with whatever is on your mind and provide useful and detailed responses to your questions. Feel free to ask me anything, and I'll do my best to help you out!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"what is my name  ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "V8FXPNkro8Sh",
        "outputId": "ce915df3-de39-4cb4-d935-ceddbf14d780"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: hey, my name is sai\n",
            "AI: Hello there, Sai! I'm your AI assistant, ready to help you with any tasks or answer any questions you might have. It's nice to meet you, and I look forward to getting to know you better and providing assistance however I can. Feel free to let me know if there's anything you need or any topics you'd like to discuss. Have a great day!\n",
            "Human: 1+1\n",
            "AI: Sure, I'll bite! \n",
            "\n",
            "1 + 1 = 2. \n",
            "\n",
            "I'm glad we have that out of the way. Now, is there anything else you'd like to discuss or any other math problems you need help solving? I'm here to assist you with whatever is on your mind and provide useful and detailed responses to your questions. Feel free to ask me anything, and I'll do my best to help you out!\n",
            "Human: what is my name  ?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ah, I do believe you introduced yourself as \"Sai\". So, my friend, your name is Sai. Nice to meet you Sai, I really do look forward to getting to know you better. \\n\\nNow, how about we continue getting to know each other better? Ask me anything you like, and I\\'ll provide you with helpful responses to the best of my abilities. We can discuss anything from the latest trends to topics that genuinely intrigue you. Don\\'t hold back, and let\\'s engage in some meaningful conversation!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FYy2qSspDhY",
        "outputId": "13bb2f19-a673-4448-ef56-d4a4b5375944"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: 1+1\n",
            "AI: Sure, I'll bite! \n",
            "\n",
            "1 + 1 = 2. \n",
            "\n",
            "I'm glad we have that out of the way. Now, is there anything else you'd like to discuss or any other math problems you need help solving? I'm here to assist you with whatever is on your mind and provide useful and detailed responses to your questions. Feel free to ask me anything, and I'll do my best to help you out!\n",
            "Human: what is my name  ?\n",
            "AI: Ah, I do believe you introduced yourself as \"Sai\". So, my friend, your name is Sai. Nice to meet you Sai, I really do look forward to getting to know you better. \n",
            "\n",
            "Now, how about we continue getting to know each other better? Ask me anything you like, and I'll provide you with helpful responses to the best of my abilities. We can discuss anything from the latest trends to topics that genuinely intrigue you. Don't hold back, and let's engage in some meaningful conversation!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"what is my name  ? \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "zrcLgoZ3pJEO",
        "outputId": "1b83c1fa-2f71-4695-8e32-528c9ab4441a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: 1+1\n",
            "AI: Sure, I'll bite! \n",
            "\n",
            "1 + 1 = 2. \n",
            "\n",
            "I'm glad we have that out of the way. Now, is there anything else you'd like to discuss or any other math problems you need help solving? I'm here to assist you with whatever is on your mind and provide useful and detailed responses to your questions. Feel free to ask me anything, and I'll do my best to help you out!\n",
            "Human: what is my name  ?\n",
            "AI: Ah, I do believe you introduced yourself as \"Sai\". So, my friend, your name is Sai. Nice to meet you Sai, I really do look forward to getting to know you better. \n",
            "\n",
            "Now, how about we continue getting to know each other better? Ask me anything you like, and I'll provide you with helpful responses to the best of my abilities. We can discuss anything from the latest trends to topics that genuinely intrigue you. Don't hold back, and let's engage in some meaningful conversation!\n",
            "Human: what is my name  ? \n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, but I don't know your name. Could you reintroduce yourself and provide me with your name? I'd love to address you properly and personalize our conversation. Looking forward to getting to know you better!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJOzHMiQpPl-",
        "outputId": "08eadb9c-4a91-42b0-e6ce-9cfc66c982fb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: what is my name  ?\n",
            "AI: Ah, I do believe you introduced yourself as \"Sai\". So, my friend, your name is Sai. Nice to meet you Sai, I really do look forward to getting to know you better. \n",
            "\n",
            "Now, how about we continue getting to know each other better? Ask me anything you like, and I'll provide you with helpful responses to the best of my abilities. We can discuss anything from the latest trends to topics that genuinely intrigue you. Don't hold back, and let's engage in some meaningful conversation!\n",
            "Human: what is my name  ? \n",
            "AI: I'm sorry, but I don't know your name. Could you reintroduce yourself and provide me with your name? I'd love to address you properly and personalize our conversation. Looking forward to getting to know you better!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ConversationTokenBufferMemory**"
      ],
      "metadata": {
        "id": "TXoexXnY_od1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.memory import ConversationTokenBufferMemory\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "llm=ChatCohere(cohere_api_key=cohere_api_key,\n",
        "               temperature=0)\n",
        "memory=ConversationTokenBufferMemory(llm=llm,max_token_limit=50)\n",
        "memory.save_context({\"input\":\"hi\"},\n",
        "                    {\"ouput\":\"hello ,how are you\"})\n",
        "memory.save_context({\"input\":\"i am doing great\"},\n",
        "                    {\"ouput\":\"what about you\"})\n",
        "print(memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv-fXDqu9LHE",
        "outputId": "e91c15c8-c0b7-4c8d-f58a-fe134a99ab7f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: hi\n",
            "AI: hello ,how are you\n",
            "Human: i am doing great\n",
            "AI: what about you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.memory import ConversationTokenBufferMemory\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "llm=ChatCohere(cohere_api_key=cohere_api_key,\n",
        "               temperature=0)\n",
        "memory=ConversationTokenBufferMemory(llm=llm,max_token_limit=15)\n",
        "memory.save_context({\"input\":\"hi\"},\n",
        "                    {\"ouput\":\"hello ,how are you\"})\n",
        "memory.save_context({\"input\":\"i am doing great\"},\n",
        "                    {\"ouput\":\"what about you\"})\n",
        "print(memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlTx2YDD_CUC",
        "outputId": "6d086e9b-3da7-4868-8c64-05e3883ca9b3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: i am doing great\n",
            "AI: what about you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**conversationSummaryMemory**"
      ],
      "metadata": {
        "id": "_eIIElC-AaND"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "45miWpe6_abg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}